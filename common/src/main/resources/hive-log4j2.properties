# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

status = INFO
name = HiveLog4j2
packages = org.apache.hadoop.hive.ql.log

# list of properties
property.hive.log.level = INFO
# Replace DRFA with routing appender to append <process-id>@<host-name> to the filename if you want separate log files for different CLI sessiong
property.hive.root.logger = DRFA
property.hive.log.dir = /opt/mapr/hive/hive-2.3/logs/${sys:user.name}
property.hive.log.file = hive.log
property.hive.perflogger.log.level = INFO

# list of all appenders. Replace DRFA with routing to enable log files separating
appenders = console, DRFA

# console appender
appender.console.type = Console
appender.console.name = console
appender.console.target = SYSTEM_ERR
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n

# daily rolling file appender
appender.DRFA.type = RollingRandomAccessFile
appender.DRFA.name = DRFA
appender.DRFA.fileName = ${sys:hive.log.dir}/${sys:hive.log.file}
appender.DRFA.filePattern = ${sys:hive.log.dir}/${sys:hive.log.file}.%d{yyyy-MM-dd}
appender.DRFA.layout.type = PatternLayout
appender.DRFA.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n
appender.DRFA.policies.type = Policies
appender.DRFA.policies.time.type = TimeBasedTriggeringPolicy
appender.DRFA.policies.time.interval = 1
appender.DRFA.policies.time.modulate = true
appender.DRFA.strategy.type = DefaultRolloverStrategy
appender.DRFA.strategy.max = 30



# PID based rolling file appender
property.filename = ${sys:hive.log.dir}/${sys:hive.log.file}

appender.routing.type = Routing
appender.routing.name = routing
appender.routing.routes.type = Routes
appender.routing.routes.pattern = $${ctx:pid}
appender.routing.routes.route1.type = Route
appender.routing.routes.route1.rolling.type = RollingFile
appender.routing.routes.route1.rolling.name = Routing-${ctx:pid}
appender.routing.routes.route1.rolling.fileName = ${filename}.${ctx:pid}
appender.routing.routes.route1.rolling.filePattern = ${sys:hive.log.dir}/${sys:hive.log.file}.${ctx:pid}.%d{yyyy-MM-dd}
appender.routing.routes.route1.rolling.layout.type = PatternLayout
appender.routing.routes.route1.rolling.layout.pattern = %d{ISO8601} %5p [%t] %pid %c{2}: %m%n
appender.routing.routes.route1.rolling.policies.type = Policies
appender.routing.routes.route1.rolling.policies.time.type = TimeBasedTriggeringPolicy
appender.routing.routes.route1.rolling.policies.time.interval = 1

appender.routing.routes.route2.type = Route
# This route is chosen if ThreadContext has no value for key pid
appender.routing.routes.route2.key=$${ctx:pid}
appender.routing.routes.route2.rolling.type = RollingFile
appender.routing.routes.route2.rolling.name = Routing-default
appender.routing.routes.route2.rolling.fileName = ${filename}-default
appender.routing.routes.route2.rolling.filePattern = ${sys:hive.log.dir}/${sys:hive.log.file}-default.%d{yyyy-MM-dd}
appender.routing.routes.route2.rolling.layout.type = PatternLayout
appender.routing.routes.route2.rolling.layout.pattern = %d{ISO8601} %5p [%t] %pid %c{2}: %m%n
appender.routing.routes.route2.rolling.policies.type = Policies
appender.routing.routes.route2.rolling.policies.time.type = TimeBasedTriggeringPolicy
appender.routing.routes.route2.rolling.policies.time.interval = 1


# list of all loggers
loggers = NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, PerfLogger

logger.NIOServerCnxn.name = org.apache.zookeeper.server.NIOServerCnxn
logger.NIOServerCnxn.level = WARN

logger.ClientCnxnSocketNIO.name = org.apache.zookeeper.ClientCnxnSocketNIO
logger.ClientCnxnSocketNIO.level = WARN

logger.DataNucleus.name = DataNucleus
logger.DataNucleus.level = ERROR

logger.Datastore.name = Datastore
logger.Datastore.level = ERROR

logger.JPOX.name = JPOX
logger.JPOX.level = ERROR

logger.PerfLogger.name = org.apache.hadoop.hive.ql.log.PerfLogger
logger.PerfLogger.level = ${sys:hive.perflogger.log.level}

# root logger
rootLogger.level = ${sys:hive.log.level}
rootLogger.appenderRefs = root
rootLogger.appenderRef.root.ref = ${sys:hive.root.logger}
